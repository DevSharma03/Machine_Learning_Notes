{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d81399b",
   "metadata": {},
   "source": [
    "# Data Wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955660f8",
   "metadata": {},
   "source": [
    "### üìå What is Data Wrangling?\n",
    "- Data wrangling is the process of cleaning, restructuring, and enriching raw data into a desired format for better decision-making in data analysis and machine learning.\n",
    "- Data wrangling (data munging) is the process of converting raw, messy data into a clean and usable format for analysis or machine learning.\n",
    "- It involves gathering, cleaning, transforming, structuring, enriching, validating, and storing data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18585cdd",
   "metadata": {},
   "source": [
    "### üîÅ Workflow of Data Wrangling\n",
    "\n",
    "| Step                       | Description                                                             |\n",
    "| -------------------------- | ----------------------------------------------------------------------- |\n",
    "| 1. **Data Collection**     | Collect data from multiple sources (CSV, APIs, databases, etc.)         |\n",
    "| 2. **Data Cleaning**       | Handle missing, incorrect, inconsistent, or duplicate data              |\n",
    "| 3. **Data Structuring**    | Convert data into a usable format (tables, data frames, etc.)           |\n",
    "| 4. **Data Transformation** | Normalize, scale, or encode values, modify formats, split/merge columns |\n",
    "| 5. **Data Enrichment**     | Add meaningful or derived columns, combine with other datasets          |\n",
    "| 6. **Validation**          | Ensure quality, accuracy, and consistency of transformed data           |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc989618",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98bbef5c",
   "metadata": {},
   "source": [
    "### üìå 1. Data Acquisition (Collecting Raw Data)\n",
    "\n",
    "| Source Type  | Examples                  | Tools Used                                   |\n",
    "| ------------ | ------------------------- | -------------------------------------------- |\n",
    "| Files        | CSV, Excel, JSON, XML     | `pandas.read_csv`, `read_excel`, `json`      |\n",
    "| Databases    | SQL, MongoDB              | `SQLAlchemy`, `PyMongo`, `pymysql`           |\n",
    "| Web APIs     | REST APIs, JSON endpoints | `requests`, `httpx`, `BeautifulSoup`, `json` |\n",
    "| Web Scraping | HTML pages                | `BeautifulSoup`, `Scrapy`, `Selenium`        |\n",
    "| IoT Devices  | Sensors, log files        | MQTT, streaming via Kafka                    |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3787a40a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18af2f7f",
   "metadata": {},
   "source": [
    "### üßº 2. Data Cleaning (Most Crucial Step)\n",
    "\n",
    "##### a. Handling Missing Values\n",
    "\n",
    "| Strategy        | Description                     | Example                       |\n",
    "| --------------- | ------------------------------- | ----------------------------- |\n",
    "| **Remove Rows** | Drop rows with `NaN` values     | `df.dropna()`                 |\n",
    "| **Fill Values** | Replace `NaN` with mean, median | `df.fillna(df['col'].mean())` |\n",
    "| **Interpolate** | Estimate missing values         | `df.interpolate()`            |\n",
    "| **Custom Fill** | Use domain logic                | `df.fillna({\"Age\": 25})`      |\n",
    "\n",
    "\n",
    "\n",
    "##### b. Removing Duplicates\n",
    "``` \n",
    "df = df.drop_duplicates()\n",
    "```\n",
    "\n",
    "\n",
    "#####  c. Correcting Data Types\n",
    "```\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df['Age'] = df['Age'].astype(int)\n",
    "```\n",
    "\n",
    "\n",
    "#####  d. Fixing Inconsistencies\n",
    "| Issue               | Fix Example                                 |\n",
    "| ------------------- | ------------------------------------------- |\n",
    "| \"usa\", \"USA\", \"UsA\" | `df['Country'] = df['Country'].str.upper()` |\n",
    "| \"\\$123\", \"123 USD\"  | Regex-based cleaning                        |\n",
    "| \"Twenty Five\"       | NLP or mapping to convert                   |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a997eb",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9840b6",
   "metadata": {},
   "source": [
    "### üèóÔ∏è 3. Data Structuring (Shaping & Indexing)\n",
    "\n",
    "##### a. Indexing\n",
    "```\n",
    "df.set_index('CustomerID', inplace=True)\n",
    "```\n",
    "\n",
    "\n",
    "##### b. Reshaping Data\n",
    "| Operation         | Description            | Function                   |\n",
    "| ----------------- | ---------------------- | -------------------------- |\n",
    "| **Melt**          | Wide ‚Üí Long format     | `pd.melt()`                |\n",
    "| **Pivot**         | Long ‚Üí Wide format     | `pivot()`, `pivot_table()` |\n",
    "| **Stack/Unstack** | Hierarchical reshaping | `stack()`, `unstack()`     |\n",
    "\n",
    "```\n",
    "df_long = pd.melt(df, id_vars=[\"Date\"], var_name=\"Metric\", value_name=\"Value\")\n",
    "df_pivot = df.pivot_table(index=\"Region\", columns=\"Year\", values=\"Sales\", aggfunc=\"sum\")\n",
    "```\n",
    "\n",
    "\n",
    "#####  c. Flattening JSON\n",
    "```\n",
    "import json\n",
    "from pandas import json_normalize\n",
    "\n",
    "data = json.loads(open(\"file.json\").read())\n",
    "df = json_normalize(data)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb24215",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82d0968",
   "metadata": {},
   "source": [
    "###  4. Data Transformation (Feature Engineering)\n",
    "\n",
    "##### a. Encoding Categorical Data\n",
    "| Technique            | Description                          | Example            |\n",
    "| -------------------- | ------------------------------------ | ------------------ |\n",
    "| **Label Encoding**   | Integer representation of categories | `LabelEncoder()`   |\n",
    "| **One-Hot Encoding** | Binary columns for each category     | `pd.get_dummies()` |\n",
    "| **Ordinal Encoding** | Map values based on order            | `map()`            |\n",
    "\n",
    "\n",
    "##### b. Scaling and Normalization\n",
    "| Method                    | Use Case              | Function           |\n",
    "| ------------------------- | --------------------- | ------------------ |\n",
    "| Min-Max Scaling           | Normalize between 0‚Äì1 | `MinMaxScaler()`   |\n",
    "| Z-Score (Standardization) | Mean = 0, Std = 1     | `StandardScaler()` |\n",
    "\n",
    "\n",
    "\n",
    "##### c. Feature Engineering\n",
    "| Technique         | Example                                             |\n",
    "| ----------------- | --------------------------------------------------- |\n",
    "| Extracting dates  | `df['Year'] = df['Date'].dt.year`                   |\n",
    "| Creating ratios   | `df['ProfitMargin'] = df['Profit'] / df['Revenue']` |\n",
    "| Combining columns | `df['FullName'] = df['First'] + ' ' + df['Last']`   |\n",
    "| Domain logic      | Create \"High Value\" customers using thresholds      |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc4e431",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15cf9e86",
   "metadata": {},
   "source": [
    "###  5. Data Enrichment (Adding Value)\n",
    "\n",
    "##### a. Merging and Joining\n",
    "~~~\n",
    "df_merged = pd.merge(df1, df2, how='left', on='CustomerID')\n",
    "~~~\n",
    "\n",
    "\n",
    "##### b. External Data Integration\n",
    "| Source         | Example                              |\n",
    "| -------------- | ------------------------------------ |\n",
    "| Geo Data       | Add state/city from postal code      |\n",
    "| Exchange Rates | Convert all to same currency         |\n",
    "| Weather API    | Add weather info for retail analysis |\n",
    "\n",
    "\n",
    "\n",
    "##### c. Derived Attributes\n",
    "```\n",
    "df['AgeGroup'] = pd.cut(df['Age'], bins=[0, 18, 60, 100], labels=[\"Child\", \"Adult\", \"Senior\"])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eaccf4b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d5baf0",
   "metadata": {},
   "source": [
    "### Data Validation\n",
    "\n",
    "##### a. Schema Validation\n",
    "Use libraries like pandera, cerberus, or custom logic.\n",
    "```\n",
    "assert df['Age'].between(0, 120).all()\n",
    "assert df['ID'].is_unique\n",
    "```\n",
    "\n",
    "\n",
    "##### b. Domain Constraints\n",
    "| Check Type       | Validation Method                          |\n",
    "| ---------------- | ------------------------------------------ |\n",
    "| Data Types       | `df.dtypes`                                |\n",
    "| Null Checks      | `df.isnull().sum()`                        |\n",
    "| Range Checks     | `df['Price'].between(0, 100000).all()`     |\n",
    "| Regex Validation | `df['Email'].str.match(r'^\\S+@\\S+\\.\\S+$')` |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
